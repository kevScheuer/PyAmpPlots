{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Aggregate and Plot AmpTools .fit Results\n",
    "If you're here, you've most likely just finished running an amplitude analysis using the [AmpTools](https://github.com/mashephe/AmpTools) framework, and now you have a whole bunch of fit results, stored as `.fit` files, that you need to start plotting. Within this tutorial you will learn how to:\n",
    "1. Aggregate these fit and data files into flattened `.csv` files\n",
    "2. Load and plot the `.csv` fit results using python's pandas and matplotlib libraries\n",
    "   1. Analyze mass independent fit results across multiple bins of invariant mass\n",
    "   1. Analyze the distributions of several fit results within a mass bin\n",
    "\n",
    "As mentioned in the [repo's README](../README.md), this tutorial assumes you are already familiar with how AmpTools functions and the basics of amplitude analysis. Please note that this tutorial will *not* cover plotting the fit's angular distributions. This requires the full information of the `.root` files and is effectively handled by the [halld_sim plotter scripts](https://github.com/JeffersonLab/halld_sim/blob/master/src/programs/AmplitudeAnalysis/vecps_plotter/vecps_plotter.cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "1. At the top right of the notebook your language / kernel is listed. Make sure `.venv (Python 3.9.18)` is selected. If the option does not appear, make sure to the virtual environment is active (see [**Setup > Python** in the README](../README.md) for details).\n",
    "2. Next we want to ensure that our GlueX environment is setup. Normally we could simply run `source setup_gluex.csh` if we were doing this in the terminal, but we'll need to go about it a special way to run this in the jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# first lets define the parent dir (repo home)\n",
    "parent_dir = str(Path().resolve().parents[0]) # 0 is the 1st parent directory, i.e. the repo home\n",
    "print(parent_dir)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, parent_dir) # add the repo home directory to the list of directories Python uses to look for modules\n",
    "\n",
    "# run the source script (done here in csh, but bash could be done instead)\n",
    "command = f\"source {parent_dir}/setup_gluex.csh && env\"\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, executable='/bin/csh')\n",
    "output, _ = proc.communicate()\n",
    "\n",
    "# Parse the environment variables\n",
    "env_vars = {}\n",
    "for line in output.decode().splitlines():\n",
    "    key, value = line.split('=', 1)\n",
    "    env_vars[key] = value\n",
    "\n",
    "# add the environment variables\n",
    "os.environ.update(env_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Aggregation\n",
    "We will want to create the following 2 files in preparation for our analysis:\n",
    "1. `data.csv`: constructed from the `.root` data files in each mass bin, containing the information for that bin\n",
    "2. `best_fits.csv`: contains all the fit results across the entire mass range, made from the \"best\" of all the randomized fits in each bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "If we want to plot our fit results, we need to include the original data we are actually fitting to. This information is unfortunately not included in the `.fit` files, so we need to read it into a `data.csv` file using [convert_to_csv.py](../scripts/convert_to_csv.py). These python scripts use `argparse`, so we can conveniently see its abilities through its help message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i $parent_dir/scripts/convert_to_csv.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now lets see what (sorted) files we are going to combine, and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i $parent_dir/scripts/convert_to_csv.py -i $parent_dir/data/*/*Amplitude.root -p\n",
    "%run -i $parent_dir/scripts/convert_to_csv.py -i $parent_dir/data/*/*Amplitude.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see a `data.csv` file here in the [analysis directory](./)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Results\n",
    "Now we will be combining all our `.fit` results across the mass bins into a flattened `.csv` file to prepare them for analysis via python. This is achieved again through the [convert_to_csv.py](../scripts/convert_to_csv.py) script, which behind the scenes interacts with [extract_fit_results.cc](../scripts/extract_fit_results.cc) to load the AmpTools `FitResults` class and import the information we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i $parent_dir/scripts/convert_to_csv.py -i $parent_dir/data/*/*best.fit -o best_fits.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass independent fit results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized fit results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: describe here how we can aggregate a csv for just a single mass bin\n",
    "\n",
    "NOTE: Aggregation need not be strictly applied to mass bin results. Bootstrap, $-t$ bins, or any other collection of `.fit` results can be grouped together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
