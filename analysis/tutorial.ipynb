{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Aggregate and Plot AmpTools .fit Results\n",
    "If you're here, you've most likely just finished running an amplitude analysis using the [AmpTools](https://github.com/mashephe/AmpTools) framework, and now you have a whole bunch of fit results, stored as `.fit` files, that you need to start plotting. Within this tutorial you will learn how to:\n",
    "1. Aggregate these fit and data files into flattened `.csv` files\n",
    "2. Load and plot the `.csv` fit results using python's pandas and matplotlib libraries\n",
    "   1. Analyze mass independent fit results across multiple bins of invariant mass\n",
    "   1. Analyze the distributions of several fit results within a mass bin\n",
    "\n",
    "As mentioned in the [repo's README](../README.md), this tutorial assumes you are already familiar with how AmpTools functions and conducts an amplitude analysis. Please note that this tutorial will *not* cover plotting the fit's angular distributions. This requires the full information of the `.root` files and is effectively handled by the [halld_sim plotter scripts](https://github.com/JeffersonLab/halld_sim/blob/master/src/programs/AmplitudeAnalysis/vecps_plotter/vecps_plotter.cc)\n",
    "\n",
    "Without further ado, lets get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Aggregation\n",
    "We will want to create the following 2 files in preparation for our analysis:\n",
    "1. `data.csv`: constructed from the `.root` data files in each mass bin, containing the information for that bin\n",
    "2. `best_fits.csv`: contains all the fit results across the entire mass range, made from the \"best\" of all the randomized fits in each bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting started, lets get the parent path of this repo for convenient file loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/w/halld-scshelf2101/kscheuer/PyAmpPlots\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "parent_dir = str(Path().resolve().parents[0]) # 0 is the 1st parent directory, i.e. the repo home\n",
    "print(parent_dir)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, parent_dir) # add the repo home directory to the list of directories Python uses to look for modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "If we want to plot our fit results, we need to include the original data we are actually fitting to. This information is unfortunately not included in the `.fit` files, so we need to read it into a `data.csv` file using [convert_to_csv.py](../scripts/convert_to_csv.py). These python scripts use `argparse`, so we can conveniently see its abilities through its help message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: convert_to_csv.py [-h] [-t {fit,root}] [-i INPUT [INPUT ...]]\n",
      "                         [-s SORTED] [-o OUTPUT] [-a ACCEPTANCE_CORRECTED]\n",
      "                         [-p]\n",
      "\n",
      "This script converts AmpTools .fit file(s) or its associated ROOT files into a\n",
      "csv. This script is used for two fit result purposes: 1. To aggregate the\n",
      "AmpTools .fit files into a single .csv file for easier analysis. 2. To convert\n",
      "the ROOT files that the .fit files are based off of into a .csv file. Behind\n",
      "the scenes, this script calls a ROOT macro for either situation.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -t {fit,root}, --type {fit,root}\n",
      "                        Type of file to convert. Can be either 'fit' for\n",
      "                        AmpTools .fit files, or 'root' for the ROOT data files\n",
      "                        that the .fit files are based off of\n",
      "  -i INPUT [INPUT ...], --input INPUT [INPUT ...]\n",
      "                        Input .fit file(s). Also accepts path(s) with a\n",
      "                        wildcard '*' and finds all matching files\n",
      "  -s SORTED, --sorted SORTED\n",
      "                        Sort the input files by last number in the file name\n",
      "                        or path. Defaults to True, so that the index of each\n",
      "                        csv row matches the ordering of the input files\n",
      "  -o OUTPUT, --output OUTPUT\n",
      "                        File name of output .csv file\n",
      "  -a ACCEPTANCE_CORRECTED, --acceptance_corrected ACCEPTANCE_CORRECTED\n",
      "                        When True, the amplitude intensities are corrected for\n",
      "                        acceptance. These are the true 'generated' values with\n",
      "                        no detector effects. Defaults to False, or the\n",
      "                        'reconstructed' values\n",
      "  -p, --preview         When passed, print out the files that will be\n",
      "                        processed and exit.\n"
     ]
    }
   ],
   "source": [
    "%run -i $parent_dir/scripts/convert_to_csv.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: complete these steps by explaining how to combine data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Results\n",
    "Now we will be combining all our `.fit` results across the mass bins into a flattened `.csv` file to prepare them for analysis via python. This is achieved again through the [convert_to_csv.py](../scripts/convert_to_csv.py) script, which behind the scenes interacts with [extract_fit_results.cc](../scripts/extract_fit_results.cc) to load the AmpTools `FitResults` class and import the information we need.\n",
    "\n",
    "TODO: complete steps for loading in just the fit files. the Rand fit analysis can be done in its own section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass independent fit results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized fit results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: describe here how we can aggregate a csv for just a single mass bin\n",
    "\n",
    "NOTE: Aggregation need not be strictly applied to mass bin results. Bootstrap, $-t$ bins, or any other collection of `.fit` results can be grouped together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
